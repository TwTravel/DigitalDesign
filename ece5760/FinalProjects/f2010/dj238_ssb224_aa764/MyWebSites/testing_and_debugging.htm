<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Testing and Debugging</title>
<!--mstheme--><link rel="stylesheet" type="text/css" href="_themes/blends/blen1011.css"><meta name="Microsoft Theme" content="blends 1011">
</head>

<body>

<p align="center"><font size="6">Testing and Debugging</font></p>
<div style="position: absolute; width: 696px; height: 552px; z-index: 1; left: 213px; top: 108px" id="layer1">
	<p class="MsoNormal"><font face="Trebuchet MS">
	<span style="line-height: 115%; letter-spacing: 1pt">This project was done 
	in steps leading up to the final goal. After each step we made sure we had 
	the current goal achieved to a satisfactory level and only then did we 
	proceed further.</span></font></p>
	<p class="MsoNormal"><font face="Trebuchet MS">
	<span style="line-height: 115%; letter-spacing: 1pt">The initial step was to 
	decide how detection of hand movement and gestures was to be done. We 
	decided to go with detection based on color recognition and wrote the code 
	accordingly. Alterations were made in the top module so that the camera 
	would only detect and display the colors we wanted which were red, green and 
	yellow. We wanted to pick a color that would not possibly be present in the 
	background or environment such as fluorescent orange, however deciding 
	threshold RGB values for the same was a problem and hence we went with 
	simple red and green.</span></font></p>
	<p class="MsoNormal"><font face="Trebuchet MS">
	<span style="line-height: 115%; letter-spacing: 1pt">To make the detection 
	mechanism light intensity independent we tried to implement the YUV scale 
	instead of the RGB scale of color patterning wherein the Y axis represents 
	light intensity and hence by ignoring the Y scale detection can be made 
	light intensity independent. However, changing to the YUV scale also did not 
	help our cause too much as it still remained intensity dependent. Hence we 
	reverted back to the RGB scale.</span></font></p>
	<p class="MsoNormal"><font face="Trebuchet MS">
	<span style="line-height: 115%; letter-spacing: 1pt">The next step was to 
	store the recorded pixel values which detected the movement of the hand. 
	Memory had to be used with care here since SRAM or M4K blocks were limited 
	and we could not store pixel addresses directly. The solution to this issue 
	was to store bits for each pixel which represented the color being detected 
	by the camera for that particular pixel which is further explained in 
	design. Once this was achieved we noticed that a lot of noisy pixels at 
	random addresses were being detected in the background. To nullify this 
	noise we decided to include the bounded box logic that is described in 
	detail in the design.</span></font></p>
	<p class="MsoNormal"><font face="Trebuchet MS">
	<span style="line-height: 115%; letter-spacing: 1pt">Bringing a cursor on 
	the screen was a little difficult as we could not send out two different 
	outputs to the VGA. However the VGA controller itself had the function of 
	displaying a cursor which we altered to suit our needs.</span></font></p>
	<p class="MsoNormal"><span style="letter-spacing: 1pt">
	<font face="Trebuchet MS">We have also assigned switch 17 on the DE2 board 
	to act as a mode selector such that when in ON position the system is in 
	debug mode where in instead of having a white canvas as the background we 
	display the current view captured by the camera on screen this was really 
	helpful in debugging the system and recalibration with changing light 
	setting. We can use Switches 0-15 to adjust the exposure rate of the camera 
	with Switch 15 being the MSB. But with increased exposure the camera frame 
	capture rate decreases so instead of increasing the exposure we used well 
	lit settings to develop the system.</font></p>
	<p class="MsoNormal"><font face="Trebuchet MS">As an added functionality in 
	our last stages of the project we tried to add depth perception of our hand 
	such that the paint brush size would vary according to the distance of the 
	hand from the sensor. So as the users hand moved closer to the sensor the 
	paint brush size would increase in pixels it drew and would decrease 
	similarly as the hand moved away. It involved minor changes in the code and 
	we were able to implement it. However it did not have reliable functionality 
	as the depth perception of the sensor was based on the number of pixels of 
	red or yellow that it detected in the entire image. However again as the 
	image being detected was not light insensitive so at the same distance from 
	the camera it was possible that the camera detected a varying amount of 
	pixels of the color being detected due to variation in light intensity in 
	various positions. Hence even though depth was maintained the paint brush 
	size would vary according to position, width, distance from light source 
	etc. So in the end we decided to not include the feature in our final 
	submission.</font></span></p>
	<p>&nbsp;</div>
<p align="left">
<!--webbot bot="Navigation" S-Type="sequence" S-Orientation="vertical" S-Rendering="graphics" B-Include-Home="FALSE" B-Include-Up="FALSE" U-Page="sid:1001" startspan --><script language="JavaScript"><!--
MSFPhover = 
  (((navigator.appName == "Netscape") && 
  (parseInt(navigator.appVersion) >= 3 )) || 
  ((navigator.appName == "Microsoft Internet Explorer") && 
  (parseInt(navigator.appVersion) >= 4 ))); 
function MSFPpreload(img) 
{
  var a=new Image(); a.src=img; return a; 
}
// --></script><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav1n=MSFPpreload("_derived/index.htm_cmp_blends010_vbtn.gif"); MSFPnav1h=MSFPpreload("_derived/index.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="index.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav1'].src=MSFPnav1h.src" onmouseout="if(MSFPhover) document['MSFPnav1'].src=MSFPnav1n.src"><img src="_derived/index.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="Home" name="MSFPnav1"></a><br><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav2n=MSFPpreload("_derived/introduction.htm_cmp_blends010_vbtn.gif"); MSFPnav2h=MSFPpreload("_derived/introduction.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="introduction.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav2'].src=MSFPnav2h.src" onmouseout="if(MSFPhover) document['MSFPnav2'].src=MSFPnav2n.src"><img src="_derived/introduction.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="Introduction" name="MSFPnav2"></a><br><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav3n=MSFPpreload("_derived/high_level_design.htm_cmp_blends010_vbtn.gif"); MSFPnav3h=MSFPpreload("_derived/high_level_design.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="high_level_design.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav3'].src=MSFPnav3h.src" onmouseout="if(MSFPhover) document['MSFPnav3'].src=MSFPnav3n.src"><img src="_derived/high_level_design.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="High Level Design" name="MSFPnav3"></a><br><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav4n=MSFPpreload("_derived/hardware_design.htm_cmp_blends010_vbtn.gif"); MSFPnav4h=MSFPpreload("_derived/hardware_design.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="hardware_design.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav4'].src=MSFPnav4h.src" onmouseout="if(MSFPhover) document['MSFPnav4'].src=MSFPnav4n.src"><img src="_derived/hardware_design.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="Hardware Design" name="MSFPnav4"></a><br><img src="_derived/testing_and_debugging.htm_cmp_blends010_vbtn_p.gif" width="140" height="60" border="0" alt="Testing &amp; Debugging"><br><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav5n=MSFPpreload("_derived/results.htm_cmp_blends010_vbtn.gif"); MSFPnav5h=MSFPpreload("_derived/results.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="results.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav5'].src=MSFPnav5h.src" onmouseout="if(MSFPhover) document['MSFPnav5'].src=MSFPnav5n.src"><img src="_derived/results.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="Results" name="MSFPnav5"></a><br><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav6n=MSFPpreload("_derived/conclusions.htm_cmp_blends010_vbtn.gif"); MSFPnav6h=MSFPpreload("_derived/conclusions.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="conclusions.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav6'].src=MSFPnav6h.src" onmouseout="if(MSFPhover) document['MSFPnav6'].src=MSFPnav6n.src"><img src="_derived/conclusions.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="Conclusions" name="MSFPnav6"></a><br><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav7n=MSFPpreload("_derived/appendix.htm_cmp_blends010_vbtn.gif"); MSFPnav7h=MSFPpreload("_derived/appendix.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="appendix.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav7'].src=MSFPnav7h.src" onmouseout="if(MSFPhover) document['MSFPnav7'].src=MSFPnav7n.src"><img src="_derived/appendix.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="Appendix" name="MSFPnav7"></a><br><script language="JavaScript"><!--
if(MSFPhover) { MSFPnav8n=MSFPpreload("_derived/references.htm_cmp_blends010_vbtn.gif"); MSFPnav8h=MSFPpreload("_derived/references.htm_cmp_blends010_vbtn_a.gif"); }
// --></script><a href="references.htm" language="JavaScript" onmouseover="if(MSFPhover) document['MSFPnav8'].src=MSFPnav8h.src" onmouseout="if(MSFPhover) document['MSFPnav8'].src=MSFPnav8n.src"><img src="_derived/references.htm_cmp_blends010_vbtn.gif" width="140" height="60" border="0" alt="References" name="MSFPnav8"></a><!--webbot bot="Navigation" i-checksum="52567" endspan --></p>

</body>

</html>
